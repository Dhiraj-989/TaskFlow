{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c226bdf7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-20T16:53:12.633281Z",
     "iopub.status.busy": "2025-04-20T16:53:12.632766Z",
     "iopub.status.idle": "2025-04-20T16:53:13.813954Z",
     "shell.execute_reply": "2025-04-20T16:53:13.812627Z"
    },
    "papermill": {
     "duration": 1.190887,
     "end_time": "2025-04-20T16:53:13.815836",
     "exception": false,
     "start_time": "2025-04-20T16:53:12.624949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with ma\n",
    "# ny helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5a6c954",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T16:53:13.829446Z",
     "iopub.status.busy": "2025-04-20T16:53:13.828902Z",
     "iopub.status.idle": "2025-04-20T16:53:23.621891Z",
     "shell.execute_reply": "2025-04-20T16:53:23.619890Z"
    },
    "papermill": {
     "duration": 9.802454,
     "end_time": "2025-04-20T16:53:23.624312",
     "exception": false,
     "start_time": "2025-04-20T16:53:13.821858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.8.5)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: pymupdf in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.6)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai) (2.28.1)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai) (2.187.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai) (2.43.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai) (5.29.5)\n",
      "Requirement already satisfied: pydantic in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai) (2.12.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-generativeai) (4.15.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core->google-generativeai) (1.72.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.5)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.31.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.1)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic->google-generativeai) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries for this notebook\n",
    "!pip install -U google-generativeai python-dotenv pymupdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e26116",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-09T13:13:02.856163Z",
     "iopub.status.busy": "2025-04-09T13:13:02.855914Z",
     "iopub.status.idle": "2025-04-09T13:13:02.863109Z",
     "shell.execute_reply": "2025-04-09T13:13:02.861760Z",
     "shell.execute_reply.started": "2025-04-09T13:13:02.856138Z"
    },
    "papermill": {
     "duration": 0.005492,
     "end_time": "2025-04-20T16:53:23.636013",
     "exception": false,
     "start_time": "2025-04-20T16:53:23.630521",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# TaskFlow: An Autonomous Research & Execution Agent üß†‚öôÔ∏è\n",
    "\n",
    "This project demonstrates a GenAI-based autonomous agent that:\n",
    "- Understands complex research queries\n",
    "- Breaks them into subtasks\n",
    "- Retrieves and summarizes relevant info using LLM\n",
    "- Outputs structured research reports (in JSON/Markdown)\n",
    "\n",
    "Models used: `gemini-1.5-pro`, `text-embedding-004`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d139c1d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T16:53:23.649147Z",
     "iopub.status.busy": "2025-04-20T16:53:23.648770Z",
     "iopub.status.idle": "2025-04-20T16:53:25.089659Z",
     "shell.execute_reply": "2025-04-20T16:53:25.088514Z"
    },
    "papermill": {
     "duration": 1.450096,
     "end_time": "2025-04-20T16:53:25.091837",
     "exception": false,
     "start_time": "2025-04-20T16:53:23.641741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.8.5'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import json\n",
    "\n",
    "# Show the installed google-generativeai version\n",
    "genai.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0661476b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-gecko-001\n",
      "models/gemini-2.5-flash\n",
      "models/gemini-2.5-pro\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.5-flash-preview-tts\n",
      "models/gemini-2.5-pro-preview-tts\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/gemma-3n-e4b-it\n",
      "models/gemma-3n-e2b-it\n",
      "models/gemini-flash-latest\n",
      "models/gemini-flash-lite-latest\n",
      "models/gemini-pro-latest\n",
      "models/gemini-2.5-flash-lite\n",
      "models/gemini-2.5-flash-image-preview\n",
      "models/gemini-2.5-flash-image\n",
      "models/gemini-2.5-flash-preview-09-2025\n",
      "models/gemini-2.5-flash-lite-preview-09-2025\n",
      "models/gemini-3-pro-preview\n",
      "models/gemini-3-pro-image-preview\n",
      "models/nano-banana-pro-preview\n",
      "models/gemini-robotics-er-1.5-preview\n",
      "models/gemini-2.5-computer-use-preview-10-2025\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/gemini-embedding-001\n",
      "models/aqa\n",
      "models/imagen-4.0-generate-preview-06-06\n",
      "models/imagen-4.0-ultra-generate-preview-06-06\n",
      "models/imagen-4.0-generate-001\n",
      "models/imagen-4.0-ultra-generate-001\n",
      "models/imagen-4.0-fast-generate-001\n",
      "models/veo-2.0-generate-001\n",
      "models/veo-3.0-generate-001\n",
      "models/veo-3.0-fast-generate-001\n",
      "models/veo-3.1-generate-preview\n",
      "models/veo-3.1-fast-generate-preview\n",
      "models/gemini-2.0-flash-live-001\n",
      "models/gemini-live-2.5-flash-preview\n",
      "models/gemini-2.5-flash-live-preview\n",
      "models/gemini-2.5-flash-native-audio-latest\n",
      "models/gemini-2.5-flash-native-audio-preview-09-2025\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "for m in genai.list_models():\n",
    "    print(m.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4531ff0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T16:53:25.105700Z",
     "iopub.status.busy": "2025-04-20T16:53:25.105013Z",
     "iopub.status.idle": "2025-04-20T16:53:25.599947Z",
     "shell.execute_reply": "2025-04-20T16:53:25.598606Z"
    },
    "papermill": {
     "duration": 0.504105,
     "end_time": "2025-04-20T16:53:25.602168",
     "exception": false,
     "start_time": "2025-04-20T16:53:25.098063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm ready. How can I help you today, or what would you like to test?\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
    "\n",
    "response = model.generate_content(\"Hello! This is a test.\")\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f332a15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T16:53:25.616300Z",
     "iopub.status.busy": "2025-04-20T16:53:25.615876Z",
     "iopub.status.idle": "2025-04-20T16:53:25.882482Z",
     "shell.execute_reply": "2025-04-20T16:53:25.881186Z"
    },
    "papermill": {
     "duration": 0.275907,
     "end_time": "2025-04-20T16:53:25.884661",
     "exception": false,
     "start_time": "2025-04-20T16:53:25.608754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.api_core import retry\n",
    "\n",
    "def is_retriable(exception):\n",
    "    return isinstance(exception, Exception) and (\n",
    "        \"429\" in str(exception) or \"503\" in str(exception)\n",
    "    )\n",
    "\n",
    "retry_wrapper = retry.Retry(predicate=is_retriable)\n",
    "\n",
    "def generate_with_retry(model, *args, **kwargs):\n",
    "    return retry_wrapper(model.generate_content)(*args, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e305d73",
   "metadata": {
    "papermill": {
     "duration": 0.005661,
     "end_time": "2025-04-20T16:53:26.005087",
     "exception": false,
     "start_time": "2025-04-20T16:53:25.999426",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Using the gemini-1.5-pro, and answering a prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39e2645b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T16:53:26.018259Z",
     "iopub.status.busy": "2025-04-20T16:53:26.017837Z",
     "iopub.status.idle": "2025-04-20T16:53:30.764381Z",
     "shell.execute_reply": "2025-04-20T16:53:30.762886Z"
    },
    "papermill": {
     "duration": 4.755484,
     "end_time": "2025-04-20T16:53:30.766532",
     "exception": false,
     "start_time": "2025-04-20T16:53:26.011048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding the \"best\" open-source LLMs depends on your specific needs, but the leaders balance performance with permissive licensing. While some are truly open-source (OSI-approved), others are \"openly available\" with commercial terms. Always consult the specific license.\n",
      "\n",
      "1.  **Llama 3 (Meta):** The latest iteration (8B, 70B models) from Meta offers state-of-the-art performance and a vast ecosystem. Its **Llama 3 Community License** is significantly more permissive than Llama 2's, allowing commercial use without the previous monthly active user (MAU) cap. This makes it a top choice for broad applications.\n",
      "\n",
      "2.  **Mistral AI Models (e.g., Mistral 7B, Mixtral 8x7B):** Mistral AI provides incredibly efficient and powerful models. Mistral 7B is an excellent small model, and Mixtral 8x7B (a sparse Mixture of Experts) delivers exceptional performance. Crucially, these foundational models are released under the highly permissive **Apache 2.0 license**, making them truly open-source and ideal for unrestricted commercial deployment.\n",
      "\n",
      "3.  **Gemma (Google):** Google's lightweight open models (2B, 7B, CodeGemma, and Gemma 2) are derived from the same research as their Gemini models. They are strong for research, smaller-scale deployments, and code generation tasks. Gemma is released under a **permissive license** (Google's specific \"Gemma Terms of Use\") that generally allows commercial use, though specific terms should be reviewed for large-scale enterprise deployments.\n",
      "\n",
      "These models offer excellent performance,\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "short_config = {\"max_output_tokens\": 2000}\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
    "\n",
    "response = model.generate_content(\n",
    "    \"Find best open-source LLMs with license info in 200 words\",\n",
    "    generation_config=short_config,\n",
    ")\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c460d34",
   "metadata": {
    "papermill": {
     "duration": 0.006044,
     "end_time": "2025-04-20T16:53:30.778824",
     "exception": false,
     "start_time": "2025-04-20T16:53:30.772780",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Responding some user queries and returning the response in json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1e3bb5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T16:53:30.792754Z",
     "iopub.status.busy": "2025-04-20T16:53:30.792377Z",
     "iopub.status.idle": "2025-04-20T16:53:36.184868Z",
     "shell.execute_reply": "2025-04-20T16:53:36.183268Z"
    },
    "papermill": {
     "duration": 5.403069,
     "end_time": "2025-04-20T16:53:36.188120",
     "exception": false,
     "start_time": "2025-04-20T16:53:30.785051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"tasks\": [\n",
      "    \"Identify current applications of AI in various sectors of sustainable development (e.g., energy, agriculture, smart cities).\",\n",
      "    \"Analyze the potential benefits and contributions of AI towards achieving specific Sustainable Development Goals (SDGs).\",\n",
      "    \"Examine the challenges, risks, and ethical considerations associated with AI deployment in sustainable development initiatives.\",\n",
      "    \"Investigate policy frameworks, governance models, and international collaborations needed to ensure responsible and equitable AI use for sustainability.\",\n",
      "    \"Explore future trends and emerging AI technologies that could further accelerate progress in sustainable development.\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import typing_extensions as typing\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "\n",
    "class TaskPlan(typing.TypedDict):\n",
    "    tasks: list[str]\n",
    "\n",
    "generation_config = {\n",
    "    \"temperature\": 0.2,\n",
    "    \"response_mime_type\": \"application/json\",\n",
    "    \"response_schema\": TaskPlan,\n",
    "}\n",
    "\n",
    "model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
    "\n",
    "def plan_tasks(topic: str):\n",
    "    response = model.generate_content(\n",
    "        f\"Break into 3‚Äì5 research tasks about: '{topic}'. \"\n",
    "        \"Return JSON with a single key 'tasks' containing an array of task strings.\",\n",
    "        generation_config=generation_config,\n",
    "    )\n",
    "    return response.text\n",
    "\n",
    "user_query = \"Role of AI in sustainable development\"  # queries\n",
    "tasks = plan_tasks(user_query)\n",
    "\n",
    "parsed_tasks = json.loads(tasks)\n",
    "print(json.dumps(parsed_tasks, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac487338",
   "metadata": {
    "papermill": {
     "duration": 0.007287,
     "end_time": "2025-04-20T16:53:36.202929",
     "exception": false,
     "start_time": "2025-04-20T16:53:36.195642",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Agent Loop\n",
    "[ User query ] ‚Üí [ Task planner ] ‚Üí [ Subtasks ] ‚Üí [ Execute each task ]\n",
    "\n",
    "- It decomposes each tasks into subtasks\n",
    "- Then executes each subtasks using GenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db713ad5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T16:53:36.216948Z",
     "iopub.status.busy": "2025-04-20T16:53:36.216558Z",
     "iopub.status.idle": "2025-04-20T16:53:42.054376Z",
     "shell.execute_reply": "2025-04-20T16:53:42.052761Z"
    },
    "papermill": {
     "duration": 5.847163,
     "end_time": "2025-04-20T16:53:42.056438",
     "exception": false,
     "start_time": "2025-04-20T16:53:36.209275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Task 1: Identify current applications of AI in various sectors of sustainable development (e.g., energy, agriculture, smart cities).\n",
      "üìù Response:\n",
      "Artificial intelligence is increasingly pivotal in driving sustainable development across diverse sectors. In the **energy sector**, AI optimizes smart grids by predicting demand and supply fluctuations, efficiently integrating renewable sources like solar and wind power, and enhancing energy conservation in buildings through predictive control systems. For **agriculture**, AI-driven precision farming minimizes resource waste; it enables intelligent irrigation, targeted fertilization based on soil and crop health data, and early detection of diseases or pests through image recognition from drones and satellites. Within **smart cities**, AI applications range from optimizing traffic flow and public transport routes to reduce congestion and emissions, to intelligent waste management systems that predict collection needs and optimize routes, thereby fostering more resource-efficient urban environments. Across these and other sectors, AI's ability to analyze vast datasets, identify patterns, and automate complex processes is accelerating progress towards more efficient, resilient, and environmentally sound practices.\n",
      "\n",
      "üîπ Task 2: Analyze the potential benefits and contributions of AI towards achieving specific Sustainable Development Goals (SDGs).\n",
      "üìù Response:\n",
      "Artificial intelligence offers transformative potential for accelerating progress across numerous Sustainable Development Goals (SDGs). For instance, in **SDG 3 (Good Health and Well-being)**, AI can revolutionize diagnostics, accelerate drug discovery, personalize treatment plans, and enhance public health surveillance to predict and mitigate disease outbreaks. Regarding **SDG 2 (Zero Hunger)**, AI-driven precision agriculture optimizes crop yields, predicts pest infestations, and minimizes waste in food supply chains. Furthermore, AI contributes significantly to **SDG 7 (Affordable and Clean Energy)** and **SDG 13 (Climate Action)** by optimizing smart grids, forecasting renewable energy generation, and modeling climate change impacts, facilitating more efficient resource management and effective mitigation strategies. By leveraging its analytical, predictive, and automation capabilities, AI can enhance efficiency, inform decision-making, and unlock innovative solutions critical for achieving a more sustainable and equitable future.\n",
      "\n",
      "üîπ Task 3: Examine the challenges, risks, and ethical considerations associated with AI deployment in sustainable development initiatives.\n",
      "üìù Response:\n",
      "Deploying AI in sustainable development initiatives presents considerable challenges, primarily stemming from data quality, availability, and the digital infrastructure disparities in many target regions. Risks include the potential to exacerbate existing inequalities, displace jobs, and introduce algorithmic biases that could lead to unfair outcomes in resource allocation or service delivery. Ethically, considerations revolve around ensuring transparency, accountability, and explainability of AI decisions, safeguarding privacy, and preventing the perpetuation of societal biases. Furthermore, the significant energy consumption of AI systems itself presents an environmental concern, underscoring the need for a responsible, equitable, and context-aware approach to harness AI's potential for good.\n",
      "\n",
      "üîπ Task 4: Investigate policy frameworks, governance models, and international collaborations needed to ensure responsible and equitable AI use for sustainability.\n",
      "üìù Response:\n",
      "Effectively harnessing AI for a sustainable future necessitates a comprehensive investigation into robust policy frameworks, encompassing ethical guidelines, regulatory standards for data governance and algorithmic transparency, and mandatory impact assessments. This must be complemented by innovative governance models that prioritize multi-stakeholder engagement, ensuring accountability mechanisms and adaptive oversight bodies can address the technology's rapid evolution and complex societal implications. Crucially, intensified international collaborations are vital to harmonize cross-border regulations, share best practices, and build shared capacity, thereby fostering responsible and equitable AI development and deployment that truly leverages its potential to accelerate solutions for climate change mitigation, resource optimization, and social equity, while diligently mitigating risks like digital divides and unintended environmental burdens.\n",
      "\n",
      "üîπ Task 5: Explore future trends and emerging AI technologies that could further accelerate progress in sustainable development.\n",
      "üìù Response:\n",
      "Future trends in AI promise transformative shifts, with emerging technologies poised to dramatically accelerate progress in sustainable development. Generative AI, for instance, can accelerate the discovery of novel sustainable materials, drug candidates, and energy solutions, while advanced AI-driven optimization algorithms will revolutionize resource management, from smart grids maximizing renewable energy integration to hyper-efficient supply chains minimizing waste. Coupled with pervasive IoT sensors and digital twins, AI can provide real-time environmental monitoring, predict climate impacts, and enable precision agriculture and circular economy models at unprecedented scales. These convergent technologies, operating at the edge and in the cloud, offer the unparalleled capacity to analyze complex systems, predict outcomes, and automate sustainable practices, thus significantly accelerating our progress towards a greener, more resilient future.\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "model = genai.GenerativeModel(model_name=\"gemini-2.5-flash\") # using a different model as gemini 1.5 pro has limitations on rpm\n",
    "\n",
    "\n",
    "\n",
    "for i, task in enumerate(parsed_tasks['tasks'], 1):\n",
    "    print(f\"\\nüîπ Task {i}: {task}\")\n",
    "    \n",
    "    # Ask Gemini to answer each task\n",
    "    response = model.generate_content(f\"Write a short paragraph on: {task}\")\n",
    "    \n",
    "    print(\"üìù Response:\")\n",
    "    print(response.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3e7fe1",
   "metadata": {
    "papermill": {
     "duration": 0.006485,
     "end_time": "2025-04-20T16:53:42.070069",
     "exception": false,
     "start_time": "2025-04-20T16:53:42.063584",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Document Understanding\n",
    "\n",
    "Reading documents and extracting text from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ad31437",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T16:53:42.086986Z",
     "iopub.status.busy": "2025-04-20T16:53:42.086481Z",
     "iopub.status.idle": "2025-04-20T16:53:49.745776Z",
     "shell.execute_reply": "2025-04-20T16:53:49.744428Z"
    },
    "papermill": {
     "duration": 7.671201,
     "end_time": "2025-04-20T16:53:49.747934",
     "exception": false,
     "start_time": "2025-04-20T16:53:42.076733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:12: SyntaxWarning: invalid escape sequence '\\G'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\G'\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_22608\\1839195758.py:12: SyntaxWarning: invalid escape sequence '\\G'\n",
      "  raw_text = extract_text_from_pdf('H:\\GATE SYLLABUS.pdf')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in c:\\users\\hp\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.26.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pymupdf\n",
    "\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "def extract_text_from_pdf(path):\n",
    "    doc = fitz.open(path)\n",
    "    text = \"\"\n",
    "    for page in doc:\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "raw_text = extract_text_from_pdf('H:\\GATE SYLLABUS.pdf')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb36799",
   "metadata": {
    "papermill": {
     "duration": 0.008487,
     "end_time": "2025-04-20T16:53:49.765152",
     "exception": false,
     "start_time": "2025-04-20T16:53:49.756665",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Breaking the long pdf into chunks so that it is made easier for the model to understand and give output efficiently with minimal errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ac2bfab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T16:53:49.782139Z",
     "iopub.status.busy": "2025-04-20T16:53:49.781771Z",
     "iopub.status.idle": "2025-04-20T16:53:49.790303Z",
     "shell.execute_reply": "2025-04-20T16:53:49.788686Z"
    },
    "papermill": {
     "duration": 0.019776,
     "end_time": "2025-04-20T16:53:49.792437",
     "exception": false,
     "start_time": "2025-04-20T16:53:49.772661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size=100, overlap=50):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = min(start + chunk_size, len(text))\n",
    "        chunks.append(text[start:end])\n",
    "        start += chunk_size - overlap\n",
    "    return chunks\n",
    "\n",
    "chunks = chunk_text(raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be76e909",
   "metadata": {
    "papermill": {
     "duration": 0.006967,
     "end_time": "2025-04-20T16:53:49.807647",
     "exception": false,
     "start_time": "2025-04-20T16:53:49.800680",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Embed the chunks\n",
    "\n",
    "Embedding the chunks into vectors for semantic understanding.\n",
    "\n",
    "using embedding model for embedding the chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1f5206b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T16:53:49.823690Z",
     "iopub.status.busy": "2025-04-20T16:53:49.823266Z",
     "iopub.status.idle": "2025-04-20T16:54:12.838397Z",
     "shell.execute_reply": "2025-04-20T16:54:12.837066Z"
    },
    "papermill": {
     "duration": 23.025452,
     "end_time": "2025-04-20T16:54:12.840309",
     "exception": false,
     "start_time": "2025-04-20T16:53:49.814857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Batching the chunks as the request is limited to 100\n",
    "import google.generativeai as genai\n",
    "import numpy as np\n",
    "\n",
    "def batch_chunks(chunks, batch_size=100):\n",
    "    for i in range(0, len(chunks), batch_size):\n",
    "        yield chunks[i:i + batch_size]\n",
    "\n",
    "all_embeddings = []\n",
    "\n",
    "for batch in batch_chunks(chunks, batch_size=100):\n",
    "    response = genai.embed_content(\n",
    "        model=\"text-embedding-004\",\n",
    "        content=batch,\n",
    "        task_type=\"semantic_similarity\",\n",
    "    )\n",
    "\n",
    "    # Case 1: batch of many ‚Üí response[\"embeddings\"]\n",
    "    if \"embeddings\" in response:\n",
    "        vectors = [item[\"embedding\"] for item in response[\"embeddings\"]]\n",
    "\n",
    "    # Case 2: batch of one ‚Üí response[\"embedding\"]\n",
    "    elif \"embedding\" in response:\n",
    "        vectors = [response[\"embedding\"]]\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected embedding response format:\", response)\n",
    "\n",
    "    # FIX: Convert token-level embeddings (N,768) to sentence-level (768,)\n",
    "    processed_vectors = []\n",
    "    for v in vectors:\n",
    "        v = np.array(v)\n",
    "        if v.ndim == 2:            # shape (N, 768)\n",
    "            v = v.mean(axis=0)     # convert to (768,)\n",
    "        processed_vectors.append(v.tolist())\n",
    "\n",
    "    all_embeddings.extend(processed_vectors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea91648",
   "metadata": {
    "papermill": {
     "duration": 0.007897,
     "end_time": "2025-04-20T16:54:12.855902",
     "exception": false,
     "start_time": "2025-04-20T16:54:12.848005",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The embeddedd vectors are now being stored in chunk_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "648020f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T16:54:12.871914Z",
     "iopub.status.busy": "2025-04-20T16:54:12.871560Z",
     "iopub.status.idle": "2025-04-20T16:54:12.888671Z",
     "shell.execute_reply": "2025-04-20T16:54:12.887262Z"
    },
    "papermill": {
     "duration": 0.027561,
     "end_time": "2025-04-20T16:54:12.890922",
     "exception": false,
     "start_time": "2025-04-20T16:54:12.863361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assuming all_embeddings and chunks are in order\n",
    "chunk_db = [\n",
    "    {\"text\": chunk, \"embedding\": embedding}\n",
    "    for chunk, embedding in zip(chunks, all_embeddings)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ca2831",
   "metadata": {
    "papermill": {
     "duration": 0.008326,
     "end_time": "2025-04-20T16:54:12.907874",
     "exception": false,
     "start_time": "2025-04-20T16:54:12.899548",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Also embedding the query into vectors so that the model can match these embedding with the relevant content from the pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78860ca9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T16:54:12.924378Z",
     "iopub.status.busy": "2025-04-20T16:54:12.923962Z",
     "iopub.status.idle": "2025-04-20T16:54:12.928907Z",
     "shell.execute_reply": "2025-04-20T16:54:12.927409Z"
    },
    "papermill": {
     "duration": 0.01543,
     "end_time": "2025-04-20T16:54:12.930839",
     "exception": false,
     "start_time": "2025-04-20T16:54:12.915409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "query = \"what is the doucment about\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e32b62bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T16:54:12.947075Z",
     "iopub.status.busy": "2025-04-20T16:54:12.946742Z",
     "iopub.status.idle": "2025-04-20T16:54:13.127730Z",
     "shell.execute_reply": "2025-04-20T16:54:13.126568Z"
    },
    "papermill": {
     "duration": 0.19152,
     "end_time": "2025-04-20T16:54:13.130032",
     "exception": false,
     "start_time": "2025-04-20T16:54:12.938512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "query_embedding_response = genai.embed_content(\n",
    "    model=\"text-embedding-004\",\n",
    "    content=query,\n",
    "    task_type=\"semantic_similarity\",\n",
    ")\n",
    "\n",
    "# Single embedding vector for the query\n",
    "query_embedding = query_embedding_response.get(\"embedding\") or query_embedding_response.get(\"embeddings\", [None])[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe62053",
   "metadata": {
    "papermill": {
     "duration": 0.006919,
     "end_time": "2025-04-20T16:54:13.144249",
     "exception": false,
     "start_time": "2025-04-20T16:54:13.137330",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Calculating the similarity scores using cosine similarity and finding the top k similar chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5092ac5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T16:54:13.160454Z",
     "iopub.status.busy": "2025-04-20T16:54:13.160018Z",
     "iopub.status.idle": "2025-04-20T16:54:13.536617Z",
     "shell.execute_reply": "2025-04-20T16:54:13.535385Z"
    },
    "papermill": {
     "duration": 0.388596,
     "end_time": "2025-04-20T16:54:13.540117",
     "exception": false,
     "start_time": "2025-04-20T16:54:13.151521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return dot(a, b) / (norm(a) * norm(b))\n",
    "\n",
    "top_k = 3\n",
    "\n",
    "scored_chunks = [\n",
    "    (cosine_similarity(np.array(query_embedding), np.array(chunk[\"embedding\"])), chunk[\"text\"])\n",
    "    for chunk in chunk_db\n",
    "]\n",
    "\n",
    "ranked_chunks = sorted(scored_chunks, key=lambda x: x[0], reverse=True)\n",
    "top_chunks = [text for _, text in ranked_chunks[:top_k]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743a5a59",
   "metadata": {
    "papermill": {
     "duration": 0.007553,
     "end_time": "2025-04-20T16:54:13.557185",
     "exception": false,
     "start_time": "2025-04-20T16:54:13.549632",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Giving a rag prompt that specifies what to do to the model\n",
    "\n",
    "and generating the output using the gemini model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "921d923f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      " \n",
      "CS Computer Science and Information Technology \n",
      "Section 1: Engineering Mathematics \n",
      "Discrete Mathe\n"
     ]
    }
   ],
   "source": [
    "print(type(chunks[0]))\n",
    "print(chunks[0][:200])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35d43e04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-20T16:54:13.575184Z",
     "iopub.status.busy": "2025-04-20T16:54:13.574705Z",
     "iopub.status.idle": "2025-04-20T16:54:19.655672Z",
     "shell.execute_reply": "2025-04-20T16:54:19.653583Z"
    },
    "papermill": {
     "duration": 6.092854,
     "end_time": "2025-04-20T16:54:19.657782",
     "exception": false,
     "start_time": "2025-04-20T16:54:13.564928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Final Answer:\n",
      " Based on the provided context, the document is about **Discrete Mathematics**, which falls under **Engineering Mathematics** within the broader field of **Computer Science and Information Technology**.\n"
     ]
    }
   ],
   "source": [
    "rag_prompt = (\n",
    "    \"Answer the following question using the provided context.\\n\\n\"\n",
    "    f\"Context:\\n{''.join(top_chunks)}\\n\\n\"\n",
    "    f\"Question:\\n{query}\"\n",
    ")\n",
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "response = genai.GenerativeModel(\"gemini-2.5-flash\").generate_content(rag_prompt)\n",
    "\n",
    "print(\"üîç Final Answer:\\n\", response.text)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7109811,
     "sourceId": 11359831,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 74.316495,
   "end_time": "2025-04-20T16:54:22.914277",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-20T16:53:08.597782",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
